{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnNR1p37/OHkAu76HT/KQb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuruvajayanth12/Neural-Networks-and-Deep-Learning/blob/main/Untitled21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# Required Libraries\n",
        "# ======================================\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "\n",
        "# ======================================\n",
        "# Download Dataset\n",
        "# ======================================\n",
        "DATA_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv\"\n",
        "LOCAL_FILE = \"fraud_transactions.csv\"\n",
        "\n",
        "def download_file(url, file_name):\n",
        "    if os.path.exists(file_name):\n",
        "        os.remove(file_name)\n",
        "    print(\"Downloading credit card fraud dataset...\")\n",
        "    urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "download_file(DATA_URL, LOCAL_FILE)\n",
        "\n",
        "# Validate file\n",
        "if os.path.getsize(LOCAL_FILE) == 0:\n",
        "    raise Exception(\"Dataset download failed!\")\n",
        "\n",
        "# ======================================\n",
        "# Load Dataset\n",
        "# ======================================\n",
        "df = pd.read_csv(LOCAL_FILE)\n",
        "print(\"Dataset loaded\")\n",
        "print(\"Rows & Columns:\", df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# ======================================\n",
        "# Import ML / DL Tools\n",
        "# ======================================\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# ======================================\n",
        "# Prepare Features and Labels\n",
        "# ======================================\n",
        "input_data = df.drop(columns=[\"Class\"])\n",
        "target_data = df[\"Class\"]\n",
        "\n",
        "# ======================================\n",
        "# Normalize Data\n",
        "# ======================================\n",
        "scaler_obj = StandardScaler()\n",
        "input_scaled = scaler_obj.fit_transform(input_data)\n",
        "\n",
        "# ======================================\n",
        "# Split Train and Test Data\n",
        "# ======================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    input_scaled,\n",
        "    target_data,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=target_data\n",
        ")\n",
        "\n",
        "# ======================================\n",
        "# Build Neural Network\n",
        "# ======================================\n",
        "fraud_detector = Sequential()\n",
        "fraud_detector.add(Dense(16, activation=\"relu\", input_dim=X_train.shape[1]))\n",
        "fraud_detector.add(Dense(8, activation=\"relu\"))\n",
        "fraud_detector.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "# ======================================\n",
        "# Compile Model\n",
        "# ======================================\n",
        "fraud_detector.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# ======================================\n",
        "# Train Model\n",
        "# ======================================\n",
        "print(\"\\nTraining started...\")\n",
        "fraud_detector.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# ======================================\n",
        "# Evaluate Model\n",
        "# ======================================\n",
        "loss, acc = fraud_detector.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"\\nTest Accuracy:\", acc)\n",
        "\n",
        "# ======================================\n",
        "# Predict One Transaction\n",
        "# ======================================\n",
        "test_input = np.array(X_test[0]).reshape(1, -1)\n",
        "fraud_score = fraud_detector.predict(test_input)[0][0]\n",
        "\n",
        "print(\"Prediction Probability:\", fraud_score)\n",
        "\n",
        "if fraud_score > 0.5:\n",
        "    print(\"Fraud\")\n",
        "else:\n",
        "    print(\"Normal\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbkbmzdW_Fza",
        "outputId": "4cba4bfe-e742-4fa1-acef-0344f86e3070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading credit card fraud dataset...\n",
            "Dataset loaded\n",
            "Rows & Columns: (284807, 31)\n",
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "1  0.125895 -0.008983  0.014724    2.69      0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
            "4  0.502292  0.219422  0.215153   69.99      0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "Training started...\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9787 - loss: 0.0643 - val_accuracy: 0.9994 - val_loss: 0.0035\n",
            "Epoch 2/5\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0034 - val_accuracy: 0.9994 - val_loss: 0.0033\n",
            "Epoch 3/5\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 0.9994 - val_loss: 0.0030\n",
            "Epoch 4/5\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9994 - val_loss: 0.0031\n",
            "Epoch 5/5\n",
            "\u001b[1m5697/5697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9993 - val_loss: 0.0034\n",
            "\n",
            "Test Accuracy: 0.9991573095321655\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
            "Prediction Probability: 3.9123242e-06\n",
            "Normal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zKh_zpSRABqo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}